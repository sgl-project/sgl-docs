{
  "$schema": "https://mintlify.com/docs.json",
  "theme": "aspen",
  "name": "SGLang Documentation",
  "colors": {
    "primary": "#d55816",
    "light": "#d55816",
    "dark": "#d55816"
  },
  "background": {
    "decoration": "grid",
    "color": {
      "dark": "#1d1d1d",
      "light": "#fffcfb"
    }
  },
  "fonts": {
    "heading": {
      "family": "Approach",
      "source": "/fonts/Approach-Medium.woff2",
      "format": "woff2",
      "weight": 500
    },
    "body": {
      "family": "Approach",
      "source": "/fonts/Approach-Regular.woff2",
      "format": "woff2",
      "weight": 400
    }
  },
  "favicon": "/favicon.png",
  "navigation": {
    "tabs": [
      {
        "tab": "Docs",
        "groups": [
          {
            "group": "Get Started",
            "pages": [
              "index",
              "docs/get-started/quickstart",
              "docs/get-started/installation"
            ]
          },
          {
            "group": "Basic Usage",
            "pages": [
              "docs/basic_usage/send_request",
              {
                "group": "OpenAI-Compatible APIs",
                "pages": [
                  "docs/basic_usage/openai_api_completions",
                  "docs/basic_usage/openai_api_vision",
                  "docs/basic_usage/openai_api_embeddings"
                ]
              },
              "docs/basic_usage/ollama_api",
              "docs/basic_usage/offline_engine_api",
              "docs/basic_usage/native_api",
              "docs/basic_usage/sampling_params",
              {
                "group": "Popular Model Usage",
                "pages": [
                  "docs/basic_usage/deepseek_v3",
                  "docs/basic_usage/deepseek_v32",
                  "docs/basic_usage/glm45",
                  "docs/basic_usage/glmv",
                  "docs/basic_usage/gpt_oss",
                  "docs/basic_usage/kimi_k2_5",
                  "docs/basic_usage/minimax_m2",
                  "docs/basic_usage/qwen3",
                  "docs/basic_usage/qwen3_vl",
                  "docs/basic_usage/llama4"
                ]
              }
            ]
          },
          {
            "group": "Advanced Features",
            "pages": [
              "docs/advanced_features/server_arguments",
              "docs/advanced_features/hyperparameter_tuning",
              "docs/advanced_features/attention_backend",
              "docs/advanced_features/speculative_decoding",
              "docs/advanced_features/structured_outputs",
              "docs/advanced_features/structured_outputs_for_reasoning_models",
              "docs/advanced_features/tool_parser",
              "docs/advanced_features/separate_reasoning",
              "docs/advanced_features/quantization",
              "docs/advanced_features/quantized_kv_cache",
              "docs/advanced_features/expert_parallelism",
              "docs/advanced_features/lora",
              "docs/advanced_features/pd_disaggregation",
              "docs/advanced_features/epd_disaggregation",
              "docs/advanced_features/pipeline_parallelism",
              {
                "group": "Hierarchical KV Caching (HiCache)",
                "pages": [
                  "docs/advanced_features/hicache_best_practices",
                  "docs/advanced_features/hicache_design",
                  "docs/advanced_features/hicache_storage_runtime_attach_detach"
                ]
              },
              "docs/advanced_features/vlm_query",
              "docs/advanced_features/dp_for_multi_modal_encoder",
              "docs/advanced_features/cuda_graph_for_multi_modal_encoder",
              "docs/advanced_features/sgl_model_gateway",
              "docs/advanced_features/deterministic_inference",
              "docs/advanced_features/observability",
              "docs/advanced_features/checkpoint_engine",
              "docs/advanced_features/sglang_for_rl"
            ]
          },
          {
            "group": "Hardware Platforms",
            "pages": [
              "docs/hardware-platforms/amd-gpus",
              {
                "group": "Ascend NPUs",
                "pages": [
                  "docs/hardware-platforms/ascend-npus/Best Practice on Ascend NPU",
                  "docs/hardware-platforms/ascend-npus/Contribution Guide",
                  "docs/hardware-platforms/ascend-npus/DeepSeek Examples",
                  "docs/hardware-platforms/ascend-npus/GLM-5",
                  "docs/hardware-platforms/ascend-npus/MindSpore Models",
                  "docs/hardware-platforms/ascend-npus/Qwen3 Examples",
                  "docs/hardware-platforms/ascend-npus/Qwen3.5",
                  "docs/hardware-platforms/ascend-npus/SGLang installation with NPUs support",
                  "docs/hardware-platforms/ascend-npus/Support Features on Ascend NPU",
                  "docs/hardware-platforms/ascend-npus/Support Models on Ascend NPU"
                ]
              },
              "docs/hardware-platforms/cpu-server",
              "docs/hardware-platforms/nvidia",
              "docs/hardware-platforms/tpu",
              "docs/hardware-platforms/xpu"
            ]
          },
          {
            "group": "Developer Guide",
            "pages": [
              "docs/developer_guide/contribution_guide",
              "docs/developer_guide/development_guide_using_docker",
              "docs/developer_guide/JIT_kernels",
              "docs/developer_guide/benchmark_and_profiling",
              "docs/developer_guide/bench_serving",
              "docs/developer_guide/evaluating_new_models"
            ]
          },
          {
            "group": "References",
            "pages": [
              "docs/references/faq",
              "docs/references/environment_variables",
              "docs/references/production_metrics",
              "docs/references/production_request_trace",
              {
                "group": "Multi-Node Deployment",
                "pages": [
                  "docs/references/multi_node_deployment/multi_node",
                  "docs/references/multi_node_deployment/deploy_on_k8s",
                  "docs/references/multi_node_deployment/lws_pd/lws_pd_deploy",
                  "docs/references/multi_node_deployment/rbg_pd/deepseekv32_pd"
                ]
              },
              "docs/references/custom_chat_template",
              {
                "group": "Frontend Language",
                "pages": [
                  "docs/references/frontend/frontend_tutorial",
                  "docs/references/frontend/choices_methods"
                ]
              },
              "docs/references/post_training_integration",
              "docs/references/learn_more"
            ]
          }
        ]
      },
      {
        "tab": "Supported Models",
        "pages": [
          "docs/supported-models",
          {
            "group": "Text generation",
            "pages": [
              "docs/supported-models/large-language-models",
              "docs/supported-models/vision-language-models",
              "docs/supported-models/diffusion-language-models"
            ]
          },
          {
            "group": "Retrieval and ranking",
            "pages": [
              "docs/supported-models/embedding-models",
              "docs/supported-models/rerank-models",
              "docs/supported-models/classification-models"
            ]
          },
          {
            "group": "Specialized models",
            "pages": [
              "docs/supported-models/reward-models"
            ]
          }
        ]
      },
      {
        "tab": "Cookbook",
        "pages": [
          "cookbook/intro",
          {
            "group": "Autoregressive Models",
            "pages": [
              {
                "group": "Qwen",
                "pages": [
                  "cookbook/autoregressive/Qwen/Qwen3.5",
                  "cookbook/autoregressive/Qwen/Qwen3",
                  "cookbook/autoregressive/Qwen/Qwen3-Next",
                  "cookbook/autoregressive/Qwen/Qwen3-VL",
                  "cookbook/autoregressive/Qwen/Qwen3-Coder-480B-A35B",
                  "cookbook/autoregressive/Qwen/Qwen2.5-VL"
                ]
              },
              {
                "group": "DeepSeek",
                "pages": [
                  "cookbook/autoregressive/DeepSeek/DeepSeek-V3_2",
                  "cookbook/autoregressive/DeepSeek/DeepSeek-V3_1",
                  "cookbook/autoregressive/DeepSeek/DeepSeek-V3",
                  "cookbook/autoregressive/DeepSeek/DeepSeek-R1",
                  "cookbook/autoregressive/DeepSeek/DeepSeek-OCR"
                ]
              },
              {
                "group": "Llama",
                "pages": [
                  "cookbook/autoregressive/Llama/Llama4-Scout",
                  "cookbook/autoregressive/Llama/Llama3.3-70B",
                  "cookbook/autoregressive/Llama/Llama3.1"
                ]
              },
              {
                "group": "GLM",
                "pages": [
                  "cookbook/autoregressive/GLM/GLM-Glyph",
                  "cookbook/autoregressive/GLM/GLM-4.5",
                  "cookbook/autoregressive/GLM/GLM-4.5V",
                  "cookbook/autoregressive/GLM/GLM-4.6",
                  "cookbook/autoregressive/GLM/GLM-4.6V",
                  "cookbook/autoregressive/GLM/GLM-4.7",
                  "cookbook/autoregressive/GLM/GLM-4.7-Flash"
                ]
              },
              {
                "group": "OpenAI",
                "pages": [
                  "cookbook/autoregressive/OpenAI/GPT-OSS"
                ]
              },
              {
                "group": "Moonshotai",
                "pages": [
                  "cookbook/autoregressive/Moonshotai/Kimi-K2",
                  "cookbook/autoregressive/Moonshotai/Kimi-Linear"
                ]
              },
              {
                "group": "MiniMax",
                "pages": [
                  "cookbook/autoregressive/MiniMax/MiniMax-M2"
                ]
              },
              {
                "group": "NVIDIA",
                "pages": [
                  "cookbook/autoregressive/NVIDIA/Nemotron3-Nano"
                ]
              },
              {
                "group": "Ernie",
                "pages": [
                  "cookbook/autoregressive/Ernie/Ernie4.5",
                  "cookbook/autoregressive/Ernie/Ernie4.5-VL"
                ]
              },
              {
                "group": "InternVL",
                "pages": [
                  "cookbook/autoregressive/InternVL/InternVL3.5"
                ]
              },
              {
                "group": "InternLM",
                "pages": [
                  "cookbook/autoregressive/InternLM/Intern-S1"
                ]
              },
              {
                "group": "Jina AI",
                "pages": [
                  "cookbook/autoregressive/Jina/Jina-reranker-m0"
                ]
              },
              {
                "group": "Mistral",
                "pages": [
                  "cookbook/autoregressive/Mistral/Mistral-3",
                  "cookbook/autoregressive/Mistral/Devstral-2"
                ]
              },
              {
                "group": "Xiaomi",
                "pages": [
                  "cookbook/autoregressive/Xiaomi/MiMo-V2-Flash"
                ]
              },
              {
                "group": "FlashLabs",
                "pages": [
                  "cookbook/autoregressive/FlashLabs/Chroma1.0"
                ]
              }
            ]
          },
          {
            "group": "Diffusion Models",
            "pages": [
              {
                "group": "FLUX",
                "pages": [
                  "cookbook/diffusion/FLUX/FLUX"
                ]
              },
              {
                "group": "Wan",
                "pages": [
                  "cookbook/diffusion/Wan/Wan2.1",
                  "cookbook/diffusion/Wan/Wan2.2"
                ]
              },
              {
                "group": "Qwen-Image",
                "pages": [
                  "cookbook/diffusion/Qwen-Image/Qwen-Image",
                  "cookbook/diffusion/Qwen-Image/Qwen-Image-Edit"
                ]
              },
              {
                "group": "Z-Image",
                "pages": [
                  "cookbook/diffusion/Z-Image/Z-Image-Turbo"
                ]
              }
            ]
          },
          {
            "group": "SpecBundle",
            "pages": [
              "cookbook/specbundle/supported_models",
              "cookbook/specbundle/specbundle_usage"
            ]
          },
          {
            "group": "Benchmarks",
            "pages": [
              "cookbook/base/benchmarks/autoregressive_model_benchmark",
              "cookbook/base/benchmarks/diffusion_model_benchmark"
            ]
          },
          {
            "group": "Reference",
            "pages": [
              "cookbook/base/reference/server_arguments"
            ]
          }
        ]
      }
    ],
    "global": {
      "anchors": [
        {
          "anchor": "SGLang",
          "href": "https://sglang.io/",
          "icon": "/favicon.png"
        },
        {
          "anchor": "GitHub",
          "href": "https://github.com/sgl-project/sglang",
          "icon": "github"
        }
      ]
    }
  },
  "logo": {
    "light": "/logo/logo.png",
    "dark": "/logo/logo.png"
  },
  "contextual": {
    "options": [
      "copy",
      "view",
      "chatgpt",
      "claude",
      "perplexity",
      "mcp",
      "cursor",
      "vscode"
    ]
  },
  "footer": {
    "socials": {
      "github": "https://github.com/sgl-project/sglang",
      "x": "https://x.com/lmsysorg",
      "linkedin": "https://www.linkedin.com/company/sgl-project/posts?feedView=all",
      "slack": "https://slack.sglang.io/",
      "discord": "https://discord.gg/4ugb2t6YY2"
    }
  }
}