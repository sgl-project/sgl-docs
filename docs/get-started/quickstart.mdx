---
title: Quickstart
---

## Install with pip or uv

It is recommended to use uv for faster installation:

<Steps>
  <Step title="Upgrade pip">
    ```bash
    pip install --upgrade pip
    ```
  </Step>
  <Step title="Install uv">
    ```bash
    pip install uv
    ```
  </Step>
  <Step title="Install SGLang">
    ```bash
    uv pip install "sglang"
    ```
  </Step>
</Steps>

### For CUDA 13

Docker is recommended (see the Docker tab on [/docs/get-started/installation](/docs/get-started/installation) for the B300/GB300/CUDA 13 note). If you do not have Docker access, follow these steps:

<Steps>
  <Step title="Install PyTorch with CUDA 13 support">
    ```bash
    # Replace X.Y.Z with the version used by your SGLang install
    uv pip install torch==X.Y.Z torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130
    ```
  </Step>
  <Step title="Install SGLang">
    ```bash
    uv pip install "sglang"
    ```
  </Step>
  <Step title="Install the sgl_kernel wheel">
    Install the `sgl_kernel` wheel for CUDA 13 from [the sgl-project whl releases](https://github.com/sgl-project/whl/blob/gh-pages/cu130/sgl-kernel/index.html). Replace `X.Y.Z` with the `sgl_kernel` version required by your SGLang install (you can find this by running `uv pip show sgl_kernel`).

    ```bash
    # x86_64
    uv pip install "https://github.com/sgl-project/whl/releases/download/vX.Y.Z/sgl_kernel-X.Y.Z+cu130-cp310-abi3-manylinux2014_x86_64.whl"

    # aarch64
    uv pip install "https://github.com/sgl-project/whl/releases/download/vX.Y.Z/sgl_kernel-X.Y.Z+cu130-cp310-abi3-manylinux2014_aarch64.whl"
    ```
  </Step>
</Steps>

### Quick fixes to common problems

- If you encounter `OSError: CUDA_HOME environment variable is not set`, set <Tooltip tip="Environment variable that points to your CUDA installation root.">CUDA_HOME</Tooltip> to your CUDA install root with either of the following solutions:
  1. Use `export CUDA_HOME=/usr/local/cuda-<your-cuda-version>` to set the `CUDA_HOME` environment variable.
  2. Install FlashInfer first following [FlashInfer installation doc](https://docs.flashinfer.ai/installation.html), then install SGLang as described above.
