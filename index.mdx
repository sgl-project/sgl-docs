---
title: Welcome to SGLang
mode: center
---

<a
  class="github-button"
  href="https://github.com/sgl-project/sglang"
  data-size="large"
  data-show-count="true"
  aria-label="Star sgl-project/sglang on GitHub"
>
  Star
</a>
<a
  class="github-button"
  href="https://github.com/sgl-project/sglang/fork"
  data-icon="octicon-repo-forked"
  data-size="large"
  data-show-count="true"
  aria-label="Fork sgl-project/sglang on GitHub"
>
  Fork
</a>
<script async defer src="https://buttons.github.io/buttons.js"></script>
<br></br>

A high-performance serving framework for large language models
and multimodal models.

<Columns cols={2}>
  <Card title="Performance & Runtime" icon="arrow-trend-up">
    Designed for low-latency, high-throughput inference with RadixAttention, prefix caching, and multi-GPU parallelism.
  </Card>

<Card title="Models & Ecosystem" icon="hexagon-nodes">
  Broad support for Llama, Qwen, DeepSeek, and more. Compatible with Hugging
  Face and OpenAI APIs.
</Card>

<Card title="Extensive Hardware Support" icon="microchip">
  Native support for NVIDIA, AMD, Intel Xeon, Google TPU, and Ascend NPU
  accelerators.
</Card>

  <Card title="Community & Training" icon="users">
    Open-source with widespread adoption, powering 400k+ GPUs and integrated with major RL frameworks.
  </Card>
</Columns>

---

## Get Started

SGLang is an inference framework meant for production level serving.<br></br>
It is designed to deliver low-latency and high-throughput inference across a wide range of setups, from a single GPU to large distributed clusters.

<Columns cols={2}>
<Card title="Install SGLang" icon="angles-down" href="/docs/get-started/installation">
  Native support for NVIDIA, AMD, Intel Xeon, Google TPU, and Ascend NPU
  accelerators.
</Card>

<Card title="Quickstart" icon="zap" href="/docs/get-started/quickstart">
  Open-source with widespread adoption, powering 400k+ GPUs and integrated with major RL frameworks.
</Card>
</Columns>
